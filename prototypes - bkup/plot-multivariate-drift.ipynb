{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate Drift {#plot_tabular_multivariate_drift}\n",
    "==================\n",
    "\n",
    "This notebooks provides an overview for using and understanding the\n",
    "multivariate drift check.\n",
    "\n",
    "**Structure:**\n",
    "\n",
    "-   [What Is Multivariate Drift?](#what-is-a-multivariate-drift)\n",
    "-   [Loading the Data](#loading-the-data)\n",
    "-   [Run the Check](#run-the-check)\n",
    "-   [Define a Condition](#define-a-condition)\n",
    "\n",
    "What Is Multivariate Drift?\n",
    "---------------------------\n",
    "\n",
    "Drift is simply a change in the distribution of data over time, and it\n",
    "is also one of the top reasons why machine learning model\\'s performance\n",
    "degrades over time.\n",
    "\n",
    "A multivariate drift is a drift that occurs in more than one feature at\n",
    "a time, and may even affect the relationships between those features,\n",
    "which are undetectable by univariate drift methods. The multivariate\n",
    "drift check tries to detect multivariate drift between the two input\n",
    "datasets.\n",
    "\n",
    "For more information on drift, please visit our\n",
    "`drift guide </user-guide/general/drift_guide>`{.interpreted-text\n",
    "role=\"doc\"}.\n",
    "\n",
    "### How Deepchecks Detects Dataset Drift\n",
    "\n",
    "This check detects multivariate drift by using\n",
    "`a domain classifier <drift_detection_by_domain_classifier>`{.interpreted-text\n",
    "role=\"ref\"}. Other methods to detect drift include\n",
    "`univariate measures <drift_detection_by_univariate_measure>`{.interpreted-text\n",
    "role=\"ref\"} which is used in other checks, such as\n",
    "`Train Test Feature Drift check </checks_gallery/tabular/train_test_validation/plot_train_test_feature_drift>`{.interpreted-text\n",
    "role=\"doc\"}.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Data\n",
    "================\n",
    "\n",
    "The dataset is the adult dataset which can be downloaded from the UCI\n",
    "machine learning repository.\n",
    "\n",
    "Dua, D. and Graff, C. (2019). UCI Machine Learning Repository\n",
    "\\[<http://archive.ics.uci.edu/ml>\\]. Irvine, CA: University of\n",
    "California, School of Information and Computer Science.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# from urllib.request import urlopen\n",
    "\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "\n",
    "from deepchecks.tabular import Dataset\n",
    "from deepchecks.tabular.datasets.classification import adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_CHUNKS = 20\n",
    "# COLORS = [\"red\", \"blue\"]\n",
    "# COLORS = [\"red\", \"blue\", \"green\", \"yellow\", \"black\", \"orange\", \"purple\", \"pink\", \"brown\", \"gray\"]\n",
    "COLORS = sns.color_palette(\"hls\", N_CHUNKS)\n",
    "\n",
    "COL_1 = 4  # prev_plan_cpu_1\n",
    "COL_1_STR = \"prev_plan_cpu_1\"\n",
    "COL_2 = 8  # prev_plan_mem_1\n",
    "COL_2_STR = \"prev_plan_mem_1\"\n",
    "\n",
    "# COL_2 = 12  # prev_instance_num_1\n",
    "# COL_2_STR = \"prev_instance_num_1\"\n",
    "\n",
    "non_feature_columns = [\n",
    "    \"name\",\n",
    "    # \"task_type\",\n",
    "    \"status\",\n",
    "    \"start_time\",\n",
    "    \"end_time\",\n",
    "    # \"instance_num\",\n",
    "    # \"plan_cpu\",\n",
    "    # \"plan_mem\",\n",
    "    \"instance_name\",\n",
    "    \"instance_name.1\",\n",
    "    \"instance_start_time\",\n",
    "    \"instance_end_time\",\n",
    "    \"machine_id\",\n",
    "    \"seq_no\",\n",
    "    \"total_seq_no\",\n",
    "    # \"instance_name\",\n",
    "    \"cpu_avg\",\n",
    "    # \"cpu_max\",\n",
    "    \"mem_avg\",\n",
    "    \"mem_max\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_output_dir(path: str, clean: bool = True) -> Path:\n",
    "    output_dir = Path(path)\n",
    "\n",
    "    if clean and output_dir.exists() and output_dir.is_dir():\n",
    "        shutil.rmtree(output_dir)\n",
    "\n",
    "    # output_dir.unlink(missing_ok=True)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset\n",
    "==============\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data(path: Path | str):\n",
    "    raw_data = pd.read_csv(path)\n",
    "\n",
    "    raw_data = (\n",
    "        raw_data.sort_values(by=[\"instance_start_time\"])\n",
    "        .drop(columns=non_feature_columns)\n",
    "        .dropna()\n",
    "    )\n",
    "\n",
    "    raw_data = raw_data[\n",
    "        (raw_data.plan_cpu > 0) & (raw_data.plan_mem > 0)\n",
    "    ]\n",
    "\n",
    "    append_prev_feature(raw_data, 4, \"plan_cpu\")\n",
    "    append_prev_feature(raw_data, 4, \"plan_mem\")\n",
    "    append_prev_feature(raw_data, 4, \"instance_num\")\n",
    "\n",
    "    raw_data = raw_data.dropna()\n",
    "\n",
    "\n",
    "    cpu_max_pred = pd.cut(\n",
    "        raw_data.cpu_max,\n",
    "        bins=4,\n",
    "        labels=[0, 1, 2, 3],\n",
    "    )\n",
    "    raw_data = raw_data.assign(\n",
    "        cpu_max_pred=cpu_max_pred,\n",
    "    )\n",
    "\n",
    "    feature_column_names += [\n",
    "        \"cpu_max_pred\",\n",
    "    ]\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    scaler = Normalizer()\n",
    "    raw_data[raw_data.columns] = scaler.fit_transform(\n",
    "        raw_data[raw_data.columns]\n",
    "    )\n",
    "    return raw_data\n",
    "\n",
    "\n",
    "def generate_data_chunks(\n",
    "    path: Path | str, out_path: Path | str\n",
    ") -> List[pd.DataFrame]:\n",
    "    path = Path(path)\n",
    "    out_path = create_output_dir(out_path, clean=False)\n",
    "\n",
    "    subsets: List[pd.DataFrame] = []\n",
    "    for i in range(N_CHUNKS):\n",
    "        if (out_path / f\"chunk-{i}.csv\").exists():\n",
    "            print(f\"Chunk {i} already exists, skip generating...\")\n",
    "            subsets.append(pd.read_csv(out_path / f\"chunk-{i}.csv\"))\n",
    "\n",
    "    if len(subsets) == N_CHUNKS:\n",
    "        return subsets\n",
    "\n",
    "    print(\"Generating data chunks...\")\n",
    "\n",
    "    raw_data = load_raw_data(path)\n",
    "\n",
    "    size = len(raw_data)\n",
    "    split_size = size // N_CHUNKS\n",
    "\n",
    "    for i in range(N_CHUNKS):\n",
    "        if i == N_CHUNKS - 1:\n",
    "            data = raw_data.iloc[i * split_size :]\n",
    "        else:\n",
    "            data = raw_data.iloc[\n",
    "                i * split_size : (i + 1) * split_size\n",
    "            ]\n",
    "        data.to_csv(out_path / f\"chunk-{i}.csv\", index=False)\n",
    "        subsets.append(data)\n",
    "\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 already exists, skip generating...\n",
      "Chunk 1 already exists, skip generating...\n",
      "Chunk 2 already exists, skip generating...\n",
      "Chunk 3 already exists, skip generating...\n",
      "Chunk 4 already exists, skip generating...\n",
      "Chunk 5 already exists, skip generating...\n",
      "Chunk 6 already exists, skip generating...\n",
      "Chunk 7 already exists, skip generating...\n",
      "Chunk 8 already exists, skip generating...\n",
      "Chunk 9 already exists, skip generating...\n",
      "Chunk 10 already exists, skip generating...\n",
      "Chunk 11 already exists, skip generating...\n",
      "Chunk 12 already exists, skip generating...\n",
      "Chunk 13 already exists, skip generating...\n",
      "Chunk 14 already exists, skip generating...\n",
      "Chunk 15 already exists, skip generating...\n",
      "Chunk 16 already exists, skip generating...\n",
      "Chunk 17 already exists, skip generating...\n",
      "Chunk 18 already exists, skip generating...\n",
      "Chunk 19 already exists, skip generating...\n"
     ]
    }
   ],
   "source": [
    "subsets = generate_data_chunks(\n",
    "    \"/lcrc/project/FastBayes/rayandrew/trace-utils/generated-task/chunk-0.csv\",\n",
    "    \"./cov-shift/alibaba/chunks-norm-new\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# label_name = 'income'\n",
    "# train_ds, test_ds = adult.load_data()\n",
    "# encoder = LabelEncoder()\n",
    "# train_ds.data[label_name] = encoder.fit_transform(train_ds.data[label_name])\n",
    "# test_ds.data[label_name] = encoder.transform(test_ds.data[label_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# train_ds.label_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Check\n",
    "=============\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# from deepchecks.tabular.checks import MultivariateDrift\n",
    "\n",
    "# check = MultivariateDrift()\n",
    "# check.run(train_dataset=subsets[0], test_dataset=subsets[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is almost no drift found between the train and the\n",
    "test set of the raw adult dataset. In addition to the drift score the\n",
    "check displays the top features that contibuted to the data drift.\n",
    "\n",
    "Introduce drift to dataset\n",
    "==========================\n",
    "\n",
    "Now, let\\'s try to add a manual data drift to the data by sampling a\n",
    "biased portion of the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from deepchecks.tabular import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    # ('handle_cat', ColumnTransformer(\n",
    "    #     transformers=[\n",
    "    #         ('num', 'passthrough',\n",
    "    #          ['numeric_with_drift', 'numeric_without_drift']),\n",
    "    #         ('cat',\n",
    "    #          Pipeline([\n",
    "    #              ('encode', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "    #          ]),\n",
    "    #          ['categorical_with_drift', 'categorical_without_drift'])\n",
    "    #     ]\n",
    "    # )),\n",
    "    ('model', DecisionTreeClassifier(random_state=0, max_depth=2))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# sample_size = 10000\n",
    "# random_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# train_drifted_df = pd.concat([train_ds.data.sample(min(sample_size, train_ds.n_samples) - 5000, random_state=random_seed), \n",
    "#                              train_ds.data[train_ds.data['sex'] == ' Female'].sample(5000, random_state=random_seed)])\n",
    "# test_drifted_df = test_ds.data.sample(min(sample_size, test_ds.n_samples), random_state=random_seed)\n",
    "\n",
    "# train_drifted_ds = Dataset(train_drifted_df, label=label_name, cat_features=train_ds.cat_features)\n",
    "# test_drifted_ds = Dataset(test_drifted_df, label=label_name, cat_features=test_ds.cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# check = MultivariateDrift()\n",
    "# check.run(train_dataset=train_drifted_ds, test_dataset=test_drifted_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the check detects a multivariate drift between the train\n",
    "and the test sets. It also displays the sex feature\\'s distribution -\n",
    "the feature that contributed the most to that drift. This is reasonable\n",
    "since the sampling was biased based on that feature.\n",
    "\n",
    "Define a Condition\n",
    "==================\n",
    "\n",
    "Now, we define a condition that enforce the multivariate drift score\n",
    "must be below 0.1. A condition is deepchecks\\' way to validate model and\n",
    "data quality, and let you know if anything goes wrong.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "check = MultivariateDrift()\n",
    "check.add_condition_overall_drift_value_less_than(0.1)\n",
    "check.run(train_dataset=train_drifted_ds, test_dataset=test_drifted_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, our condition successfully detects the drift score is above\n",
    "the defined threshold.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
